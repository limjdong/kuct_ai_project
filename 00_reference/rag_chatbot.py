import streamlit as st
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.chat_models import ChatOpenAI
from langchain_core.runnables import RunnableLambda
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv
import hashlib

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv("env.txt")

# ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• 
def load_and_split_docs(uploaded_file):
    with open(uploaded_file.name, "wb") as f:
        f.write(uploaded_file.getbuffer())

    if uploaded_file.name.endswith(".pdf"):
        loader = PyPDFLoader(uploaded_file.name)
    else:
        loader = TextLoader(uploaded_file.name, encoding="utf-8")

    documents = loader.load()
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
    return splitter.split_documents(documents)

# ë²¡í„° ì €ì¥ì†Œ ìƒì„± (FAISS ì‚¬ìš©)
def get_vectorstore(docs):
    embeddings = OpenAIEmbeddings()
    return FAISS.from_documents(docs, embeddings)

# RAG ì²´ì¸ êµ¬ì„±
def build_rag_chain(vectordb):
    retriever = vectordb.as_retriever()
    prompt = ChatPromptTemplate.from_template(
        """
        ë„ˆëŠ” ë°˜ë„ì²´ ê¸°ìˆ  ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” AIì•¼.
        ì£¼ì–´ì§„ ë¬¸ì„œë¥¼ ì°¸ê³ í•´ ì•„ë˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µí•´:

        ì§ˆë¬¸: {question}

        ì°¸ê³  ë¬¸ì„œ:
        {context}
        """
    )
    llm = ChatOpenAI(model="openai/gpt-4.1-mini", temperature=0)
    rag_chain = (
        {
            "context": RunnableLambda(lambda x: x["question"]) | retriever,
            "question": RunnableLambda(lambda x: x["question"])
        }
        | prompt
        | llm
    )
    return rag_chain

# Streamlit UI
st.set_page_config(page_title="ë°˜ë„ì²´ ë¬¸ì„œ RAG ì±—ë´‡")
st.title("ğŸ“˜ ë°˜ë„ì²´ ê¸°ìˆ ë¬¸ì„œ ìš”ì•½ ë° ì§ˆì˜ì‘ë‹µ ì±—ë´‡")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "uploaded_file_hash" not in st.session_state:
    st.session_state.uploaded_file_hash = None
if "vectordb" not in st.session_state:
    st.session_state.vectordb = None
if "rag_chain" not in st.session_state:
    st.session_state.rag_chain = None

# íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (PDF ë˜ëŠ” TXT)", type=["pdf", "txt"])

# íŒŒì¼ í•´ì‹œ ê³„ì‚° í•¨ìˆ˜
def get_file_hash(file_bytes):
    return hashlib.md5(file_bytes).hexdigest()

if uploaded_file:
    file_hash = get_file_hash(uploaded_file.getvalue())

    # ì´ì „ íŒŒì¼ê³¼ ë‹¤ë¥´ë©´ ì´ˆê¸°í™”
    if st.session_state.uploaded_file_hash != file_hash:
        st.session_state.uploaded_file_hash = file_hash
        st.session_state.vectordb = None
        st.session_state.rag_chain = None

        with st.spinner("ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ê³  ì„ë² ë”© ì¤‘ì…ë‹ˆë‹¤..."):
            split_docs = load_and_split_docs(uploaded_file)
            st.session_state.vectordb = get_vectorstore(split_docs)
            st.session_state.rag_chain = build_rag_chain(st.session_state.vectordb)
            st.success("âœ… ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ! ì§ˆë¬¸ì„ ì…ë ¥í•´ë³´ì„¸ìš”.")

    question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
    if question and st.session_state.rag_chain:
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            result = st.session_state.rag_chain.invoke(
                {"question": question},
            )
            st.write("### ğŸ“ ë‹µë³€:")
            st.write(result.content)
else:
    st.info("PDF ë˜ëŠ” í…ìŠ¤íŠ¸ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
