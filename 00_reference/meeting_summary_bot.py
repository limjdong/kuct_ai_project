import os
import gradio as gr
from dotenv import load_dotenv
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.chat_models import ChatOpenAI
from langchain_core.runnables import RunnableLambda
from langchain_community.document_loaders import TextLoader

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv("env.txt")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# LLM ì´ˆê¸°í™”
llm = ChatOpenAI(model="openai/gpt-4.1-mini", temperature=0.3)

# ë³´ê³ ì„œ í”„ë¡¬í”„íŠ¸
report_prompt = ChatPromptTemplate.from_template("""
ë‹¤ìŒì€ ë‚´ë¶€ íšŒì˜ë¡ì…ë‹ˆë‹¤.

íšŒì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í˜•ì‹ì˜ **íšŒì˜ ìš”ì•½ ë³´ê³ ì„œ**ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

---

 **1. íšŒì˜ ì œëª© ë˜ëŠ” ì£¼ì œ**  
(í•µì‹¬ ì£¼ì œë¥¼ ëª…í™•í•˜ê²Œ ì„œìˆ )

 **2. ì£¼ìš” ë…¼ì˜ì‚¬í•­ ìš”ì•½**  
- í•­ëª©ë³„ë¡œ í•µì‹¬ ë…¼ì˜ ë‚´ìš©ì„ ì •ë¦¬

---

íšŒì˜ë¡ ì „ë¬¸:
===========
{meeting_text}
""")

rag_chain = (
    {"meeting_text": lambda x: x["text"]}
    | report_prompt
    | llm
)

# í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë”
def load_txt_file(file_path):
    loader = TextLoader(file_path, encoding="utf-8")
    docs = loader.load()
    return "\n".join([doc.page_content for doc in docs])

# íšŒì˜ë¡ ìš”ì•½ í•¨ìˆ˜
def summarize_report(file):
    # íŒŒì¼ ì´ë¦„ì—ì„œ ìˆœìˆ˜ íŒŒì¼ëª…ë§Œ ì¶”ì¶œ
    file_path = file.name  # ê²½ë¡œ ì¶”ì¶œ
    text = load_txt_file(file_path)  # TextLoaderë¡œ ë¡œë“œ
    result = rag_chain.invoke({"text": text})  # LangChain ì²´ì¸ ì‹¤í–‰
    return result.content

# Gradio UI êµ¬ì„±
with gr.Blocks() as demo:
    gr.Markdown("## ğŸ§¾ íšŒì˜ë¡ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±ê¸° (.txt ì „ìš©)")
    gr.Markdown("ì‚¬ë‚´ íšŒì˜ë¡(.txt)ì„ ì—…ë¡œë“œí•˜ë©´, ì¼ë°˜ì ì¸ ë³´ê³ ì„œ í˜•ì‹ìœ¼ë¡œ ìë™ ìš”ì•½í•´ë“œë¦½ë‹ˆë‹¤.")

    file_input = gr.File(label="ğŸ“‚ íšŒì˜ë¡ ì—…ë¡œë“œ (.txt í˜•ì‹ë§Œ ê°€ëŠ¥)", type="filepath", file_types=[".txt"])
    output = gr.Textbox(label="ğŸ“‹ ìƒì„±ëœ íšŒì˜ ë³´ê³ ì„œ", lines=25)

    submit_btn = gr.Button("ğŸ“ ë³´ê³ ì„œ ìƒì„±")

    submit_btn.click(fn=summarize_report, inputs=file_input, outputs=output)

demo.launch()
